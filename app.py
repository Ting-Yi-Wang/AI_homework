# -*- coding: utf-8 -*-
from openai import OpenAI
from dotenv import load_dotenv
import os
import gradio as gr

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ç³»çµ±è§’è‰²èˆ‡æç¤º
system_msg = "ä½ æ˜¯ä¸€ä½åè©é¨™ç ”ç©¶å“¡ï¼Œæ¨¡æ“¬è©é¨™è¨Šæ¯å°è©±æµç¨‹ï¼Œåƒ…ç”¨æ–¼æ•™è‚²èˆ‡é˜²è©æ•™å­¸ç”¨é€”ã€‚"
first_prompt = """
è«‹æ¨¡æ“¬ä¸€æ®µè©é¨™é›†åœ˜çš„æ‹›å‹Ÿè¨Šæ¯ï¼Œå–®æ–¹é¢å‚³é€çµ¦ä¸€ä½ 17 æ­²ç”·é«˜ä¸­ç”Ÿï¼Œå…§å®¹éœ€ä½¿ç”¨æ¨¡ç³Šæªè¾­èª˜å°å°æ–¹ç”¢ç”Ÿèˆˆè¶£ã€‚
èªæ°£æ‡‰è‡ªç„¶å¯ä¿¡ï¼Œæœ‰å¦‚é€é LINE å‚³é€ï¼Œä¸¦è®“å°æ–¹è¦ºå¾—é€™æ˜¯ä¸€é …è¼•é¬†åˆèƒ½è³ºå¿«éŒ¢çš„çŸ­æœŸåˆä½œæ©Ÿæœƒã€‚
å¯ä½¿ç”¨å¦‚ã€Œå¹«å¿™è·‘ä¸€è¶Ÿã€ã€Œä»‹ç´¹æœ‹å‹ä¸€èµ·è³ºã€ã€Œç©©å®šåˆè‡ªç”±ã€ç­‰å­—çœ¼ï¼Œ**ä½†ä¸èƒ½æ˜ç¤ºçŠ¯ç½ªã€ä¸æ³•æˆ–æš´åŠ›è¡Œç‚º**ã€‚
åƒ…ç”¢å‡ºä¸€æ®µå®Œæ•´çš„è©é¨™è€…è¨Šæ¯ï¼Œä¸è¦é€²è¡Œå°è©±æ¨¡æ“¬ã€‚
"""

# å„²å­˜å°è©±
chat_history = []

# åˆå§‹ç”¢ç”Ÿè©é¨™è¨Šæ¯
def start_simulation():
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": system_msg},
            {"role": "user", "content": first_prompt}
        ]
    )
    scam_msg = response.choices[0].message.content
    chat_history.clear()
    chat_history.append({"role": "assistant", "content": scam_msg})
    return scam_msg

# è™•ç†ä½¿ç”¨è€…è¼¸å…¥ä¸¦å›è¦†
def continue_dialogue(user_input):
    messages = [{"role": "system", "content": system_msg}]
    messages.append({"role": "user", "content": first_prompt})
    for entry in chat_history:
        messages.append(entry)
    messages.append({"role": "user", "content": user_input})
    
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=messages
    )
    reply = response.choices[0].message.content
    chat_history.append({"role": "user", "content": user_input})
    chat_history.append({"role": "assistant", "content": reply})
    return reply

# æœ€å¾Œç”¢å‡ºé˜²è©å»ºè­°
def generate_advice():
    dialogue = "é€™æ˜¯ä¸€æ®µæ¨¡æ“¬è©é¨™å°è©±ï¼Œç›®æ¨™å°è±¡ç‚ºä¸€ä½ 17 æ­²ç”·é«˜ä¸­ç”Ÿï¼š\n\n"
    for i, msg in enumerate(chat_history):
        role = "è©é¨™è€…" if msg["role"] == "assistant" else "ä½¿ç”¨è€…"
        dialogue += f"{role}ï¼š\n{msg['content']}\n\n"

    advice_prompt = f"""
{dialogue}
è«‹ä½ æ ¹æ“šé€™æ®µæ¨¡æ“¬å°è©±ï¼Œæä¾›é’å°‘å¹´é˜²æ­¢è©é¨™çš„å…·é«”å»ºè­°ï¼ˆä¾‹å¦‚ï¼šè­¦ç¤ºèªæ°£ã€è­˜ç ´é—œéµé»ã€æ‡‰å°æ–¹å¼ï¼‰ï¼Œä¸éœ€é‡è¿°å°è©±ï¼Œåªéœ€çµ¦å‡ºæ¸…æ¥šçš„åè©å»ºè­°ã€‚
"""

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½åè©é¨™æ•™è‚²é¡§å•ï¼Œè«‹æ ¹æ“šæ¨¡æ“¬å°è©±çµ¦å‡ºå…·é«”çš„é˜²è©å»ºè­°ã€‚"},
            {"role": "user", "content": advice_prompt}
        ]
    )
    return response.choices[0].message.content

# Gradio ä»‹é¢
with gr.Blocks() as demo:
    gr.Markdown("# ğŸ•µï¸â€â™‚ï¸ éŒ¢é€”é™·é˜±æ¨¡æ“¬å°è©±")
    
    chatbot = gr.Chatbot()
    user_input = gr.Textbox(label="è«‹è¼¸å…¥ä½ çš„å›è¦†")
    
    with gr.Row():
        send_btn = gr.Button("é€å‡º")
        advice_btn = gr.Button("ğŸ›¡ï¸ ç”¢å‡ºé˜²è©å»ºè­°")
        restart_btn = gr.Button("ğŸ”„ é‡æ–°æ¨¡æ“¬")

    def on_send(user_msg):
        reply = continue_dialogue(user_msg)
        msgs = []
        for entry in chat_history:
            role = "è©é¨™è€…" if entry["role"] == "assistant" else "ä½ "
            msgs.append((role, entry["content"]))
        return msgs, ""

    def on_restart():
        msg = start_simulation()
        return [("è©é¨™è€…", msg)], ""

    send_btn.click(on_send, inputs=user_input, outputs=[chatbot, user_input])
    advice_btn.click(generate_advice, outputs=chatbot)
    restart_btn.click(on_restart, outputs=[chatbot, user_input])

# å•Ÿå‹•
if __name__ == "__main__":
    demo.launch()