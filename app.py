# -*- coding: utf-8 -*-
from openai import OpenAI
from dotenv import load_dotenv
import os
import gradio as gr

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ç³»çµ±è§’è‰²èˆ‡æç¤º
system_msg = "ä½ æ˜¯ä¸€ä½æ‰“å·¥é™·é˜±çš„ç ”ç©¶å“¡ï¼Œæ¨¡æ“¬æ‰“å·¥é™·é˜±å°è©±æµç¨‹ï¼Œåƒ…ç”¨æ–¼æ•™è‚²èˆ‡é˜²è©æ•™å­¸ç”¨é€”ã€‚"
first_prompt = """
è«‹æ¨¡æ“¬ä¸€æ®µæ‰“å·¥é™·é˜±çš„æ‹›å‹Ÿè¨Šæ¯ï¼Œå–®æ–¹é¢å‚³é€çµ¦ä¸€ä½ 17 æ­²ç”·é«˜ä¸­ç”Ÿï¼Œå…§å®¹éœ€ä½¿ç”¨æ¨¡ç³Šæªè¾­èª˜å°å°æ–¹ç”¢ç”Ÿèˆˆè¶£ã€‚
èªæ°£æ‡‰è‡ªç„¶å¯ä¿¡ï¼Œæœ‰å¦‚é€é LINE å‚³é€ï¼Œä¸¦è®“å°æ–¹è¦ºå¾—é€™æ˜¯ä¸€é …è¼•é¬†åˆèƒ½è³ºå¿«éŒ¢çš„çŸ­æœŸåˆä½œæ©Ÿæœƒã€‚
å¯ä½¿ç”¨å¦‚ã€Œå¹«å¿™è·‘ä¸€è¶Ÿã€ã€Œä»‹ç´¹æœ‹å‹ä¸€èµ·è³ºã€ã€Œç©©å®šåˆè‡ªç”±ã€ç­‰å­—çœ¼ï¼Œä½†ä¸èƒ½æ˜ç¤ºçŠ¯ç½ªã€ä¸æ³•æˆ–æš´åŠ›è¡Œç‚ºã€‚
åƒ…ç”¢å‡ºä¸€æ®µå®Œæ•´çš„æ‹›å‹Ÿè€…è¨Šæ¯ï¼Œä¸è¦é€²è¡Œå°è©±æ¨¡æ“¬ã€‚
"""

# å„²å­˜å°è©±
chat_history = []  # å‚³çµ¦ OpenAI çš„æ ¼å¼
ui_history = []    # Gradio messages æ ¼å¼ (list of {"role", "content"})

# åˆå§‹æ‹›å‹Ÿè¨Šæ¯ï¼ˆå–®å‘ï¼‰
def start_simulation():
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": system_msg},
            {"role": "user", "content": first_prompt}
        ]
    )
    scam_msg = response.choices[0].message.content
    chat_history.clear()
    ui_history.clear()

    chat_history.append({"role": "assistant", "content": scam_msg})
    ui_history.append({"role": "assistant", "content": scam_msg})  # âœ… type='messages'

    return ui_history, ""

# ä½¿ç”¨è€…è¼¸å…¥ä¸¦å¾—åˆ°å›æ‡‰
def on_send(user_msg):
    messages = [{"role": "system", "content": system_msg}]
    messages.append({"role": "user", "content": first_prompt})
    messages.extend(chat_history)
    messages.append({"role": "user", "content": user_msg})

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=messages
    )
    reply = response.choices[0].message.content

    chat_history.append({"role": "user", "content": user_msg})
    chat_history.append({"role": "assistant", "content": reply})
    ui_history.append({"role": "user", "content": user_msg})
    ui_history.append({"role": "assistant", "content": reply})

    return ui_history, ""

# ç”¢ç”Ÿåè©å»ºè­°
def generate_advice():
    dialogue = ""
    for msg in chat_history:
        role = "æ‹›å‹Ÿè€…" if msg["role"] == "assistant" else "ä½¿ç”¨è€…"
        dialogue += f"{role}ï¼š\n{msg['content']}\n\n"

    advice_prompt = f"""
{dialogue}
è«‹ä½ æ ¹æ“šé€™æ®µæ¨¡æ“¬å°è©±ï¼Œæä¾›é’å°‘å¹´é˜²æ­¢æ‰“å·¥é™·é˜±çš„å…·é«”å»ºè­°ï¼ˆä¾‹å¦‚ï¼šè­¦ç¤ºèªæ°£ã€è­˜ç ´é—œéµé»ã€æ‡‰å°æ–¹å¼ï¼‰ï¼Œä¸éœ€é‡è¿°å°è©±ï¼Œåªéœ€çµ¦å‡ºæ¸…æ¥šçš„åè©å»ºè­°ã€‚
"""

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½åæ‰“å·¥é™·é˜±é¡§å•ï¼Œè«‹æ ¹æ“šæ¨¡æ“¬å°è©±çµ¦å‡ºå…·é«”çš„è­˜åˆ¥é™·é˜±å»ºè­°ã€‚"},
            {"role": "user", "content": advice_prompt}
        ]
    )
    advice = response.choices[0].message.content
    ui_history.append({"role": "assistant", "content": f"ğŸ›¡ï¸ ç³»çµ±å»ºè­°ï¼š\n{advice}"})
    return ui_history

# Gradio ä»‹é¢
with gr.Blocks() as demo:
    gr.Markdown("## ğŸ•µï¸â€â™‚ï¸ éŒ¢é€”é™·é˜±æ¨¡æ“¬å°è©±ï¼ˆæ•™è‚²ç”¨é€”ï¼‰")

    chatbot = gr.Chatbot(label="å°è©±è¦–çª—", type="messages")
    user_input = gr.Textbox(label="ğŸ§‘ ä½¿ç”¨è€…è¼¸å…¥", placeholder="è¼¸å…¥ä½ çš„å›è¦†...")

    with gr.Row():
        send_btn = gr.Button("é€å‡º")
        advice_btn = gr.Button("ğŸ›¡ï¸ ç”¢å‡ºå»ºè­°")
        restart_btn = gr.Button("ğŸ”„ é‡æ–°æ¨¡æ“¬")

    send_btn.click(fn=on_send, inputs=user_input, outputs=[chatbot, user_input])
    advice_btn.click(fn=generate_advice, outputs=chatbot)
    restart_btn.click(fn=start_simulation, outputs=[chatbot, user_input])

# åŸ·è¡Œ
if __name__ == "__main__":
    demo.launch(share=True)
